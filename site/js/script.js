var newsArray =[
	{//18
		date: "April 2020",
		startContent: 'New arXiv paper:',
		linkTo: 'https://arxiv.org/abs/2004.10141',
		linkName: 'TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition.',
		continueContent: ''
	},
	{//17
		date: "March 2020",
		startContent: 'IBM Research Blog',
		linkTo: 'https://www.ibm.com/blogs/research/2020/03/benefits-ai-for-breast-cancer-detection/',
		linkName: 'The potential benefits of AI for breast cancer detection.',
		continueContent: ''
	},
	{//16
		date: "March 2020",
		startContent: "New arXiv paper:",
		linkTo: 'https://arxiv.org/abs/2003.03186',
		linkName: 'Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning.',
		continueContent: ''
	},
	{//15
		date: "March 2020",
		startContent: 'New paper:',
		linkTo: 'https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2761795',
		linkName: '"Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms", JAMA Networks Open.',
		continueContent: ''
	},
	{//14
		date: "February 2020",
		startContent: 'Our workshop proposal',
		linkTo: 'https://sites.google.com/view/multimodalvideo-v2/',
		linkName: 'Workshop on multi-modal video analysis and moments in time", JAMA Networks Open.',
		continueContent: 'has been accepted for ECCV 2020.'
	},
	{//13
		date: "October 2019",
		startContent: 'Paper "Learning to Detect and Retrieve Objects from Unlabeled Videos", Workshop on multi-modal video analysis and moments in time.',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//12
		date: "June 2019",
		startContent: 'Paper "Mammogram Classification with Ordered Loss" was nominated for the best paper award at AIME 2019.',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//11
		date: "May 2019",
		startContent: 'New arXiv paper: "Toward Self-Supervised Object Detection in Unlabeled Videos".',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//10
		date: "May 2019",
		startContent: 'New arXiv paper: "A dual branch deep neural network for classification and detection in mammograms".',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//9
		date: "March 2019",
		startContent: 'New paper "Mammogram Classification with Ordered Loss" accepted to AIME 2019.',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//8
		date: "December 2018",
		startContent: 'New paper "Classification and detection in mammogram with weak supervision via dual branch deep neural network" accepted to ISBI 2019.',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//7
		date: "November 2018",
		startContent: 'Patent "SYSTEMS AND METHODS FOR AUTOMATIC DETECTION OF ARCHITECTURAL DISTORTION IN TWO DIMENSIONAL MAMMOGRAPHIC IMAGES" Granted.',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//6
		date: "October 2018",
		startContent: 'New position at IBM Research - Computer Vision and Deep Learning Technical Lead, Video-AI',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//5
		date: "August 2018",
		startContent: 'Patent Granted: Systems and Methods for Automatic Detection of Architectural Distortion in Two Dimensional Mammographic Images',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//4
		date: "June 2018",
		startContent: 'Patent Granted: Automated Fibro-Glandular Tissue Segmentation in Digital Mammography Using Fuzzy Logic',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//3
		date: "April 2018",
		startContent: 'New paper accepted to ICPR 2018: Unsupervised clustering of mammograms for outlier detection and breast density estimation',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//2
		date: "March 2018",
		startContent: 'Teaching a new course at Bar-Ilan University: Decision Support Systems in Medical Imaging',
		linkTo: '',
		linkName: '',
		continueContent: ''
	},
	{//1
		date: "March 2018",
		startContent: 'Organizer of the special session "Building the biggest challenge in digital mammopgraphy" at BHI 2018,',
		linkTo: 'https://bhi-bsn.embs.org/2018/wp-content/uploads/sites/40/2018/02/BHI_SS.pdf',
		linkName: 'PDF',
		continueContent: ''
	}
];

var supervisionArray = [
	{
		name: "Mor Shpigel-Nacson",
		content: "Intern (MSc student), Technion."
	},
	{
		name: "Eald Amrani",
		content: "MSc (joint with Prof. Alex Bronstein), Technion."
	},
	{
		name: "Doron Elad",
		content: "Postdoc (joint with Prof. Ofer Pasternak and Prof. Nir Sochen), Tel-Aviv University."
	},
	{
		name: "Ran Bakalo",
		content: "MSc (joint with Prof. Jacob Goldberger), Haifa University, 2018."
	},
	{
		name: "Ran Ben-Yitshak",
		content: "Intern (MSc student), Technion, 2017."
	},
	{
		name: "Jeremias Sulam",
		content: "Intern (PhD student), Technion, 2016."
	},
	{
		name: "Yuval Frommer",
		content: "MSc (joint with Prof. Nahum Kiryati), Tel-Aviv University, 2015."
	},
	{
		name: "Tomer Livneh and Dan Smamah",
		content: "Graduate project, Tel-Aviv University, 2015."
	}
];

var publicationsArray = [
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E.Amrani, O. Azulai, U. Barzelay and D. Rotman",
		title: "TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition,",
		linkTo: "#",
		linkName: "arXiv, 2020",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "E.Amrani,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "D. Rotman and A. Bornstein",
		title: "Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms,",
		linkTo: "#",
		linkName: " JAMA Network Open, 2020.",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "T. Shaffter et. al.",
		RamiBenAri: "",
		namesAfterRami: "",
		title: "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning,",
		linkTo: "#",
		linkName: "arXiv, 2020",
		achievement: "This research has been covered by 22 outlets around the globe, totaling more than 36.6 million earned media impressions by March 2020.",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "E. Amrani,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "T. Hakim and A. Bornstein",
		title: "Toward Self-Supervised Object Detection in Unlabeled Videos,",
		linkTo: "#",
		linkName: "ICCV Workshop on Multimodal Video Analysis and Moments in Time, 2019",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "R. Bakalo, J. Goldberger and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "T. Hakim and A. Bornstein",
		title: "Weakly and Semi Supervised Detection in Medical Imaging via Deep Dual Branch Net,",
		linkTo: "#",
		linkName: "arXiv, 2019",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "Y. Shoshan and T. Tlusty",
		title: "Mammogram Classification with Ordered Loss, Artificial Intelligence in Medicine 2019 (Oral)-20% acceptance rate,",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "Nominated for the best paper award.",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Breast radiologists inspect mammograms with the utmost consideration to capture true cancer cases. Yet, machine learning models are typically designed to perform a binary classification, by joining several severities into one positive class. In such scenarios with mixed gradings, a reliable classifier would make less mistakes between distant severities such as missing a true cancer case and calling it as normal or vise versa. To this end, we suggest a simple yet elegant formulation for training a deep learning model with ordered loss, by increasingly weighting the loss of more severe cases, to enforce importance of certain errors over others. Training with the ordered loss yields fewer severe errors and can decrease the chances of missing true cancers. We evaluated our method on mammogram classification, using a weakly supervised deep learning method. Our data set included over 16K mammograms, with a large set of nearly 2,500 biopsy proven cancer cases. Evaluation of our proposed loss function showed a reduction in severe errors of missing true cancers, while preserving overall classification performance in the original task."
	},
	{
		namesBeforeRami: "R. Bakalo,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and J. Goldberger",
		title: "Unsupervised clustering of mammograms for outlier detection and breast density estimation,ICPR 2018,",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "The flourishing of machine learning use for cognitive tasks has driven an increased demand for large annotated training datasets. In the medical imaging domain, such datasets are scarce, and the process of labeling them is costly, error prone and requires high expertise. Unsupervised learning is therefore an attractive approach for analyzing unlabeled medical images. In this paper we describe an unsupervised analysis method, consisting of feature learning by Stacked Auto-Encoders, K-means clustering for building a data model, and encoding of new images using the model. We utilize this method for image-level and patch-level analysis of breast mammograms. At the image-level, we demonstrate that our cluster-based image encoding is able to identify outlier images such as images with implants or non-standard acquisition views. At the patch-level, we show that image signatures using patch clustering can be used for unsupervised semantic segmentation of breast tissues, as well as for separating mammograms with high and low breast density. We evaluate our suggested methods on large datasets and discuss potential applications for data curation, machine-guided annotation and automatic interpretation of medical images."
	},
	{
		namesBeforeRami: "T. Tlustly, G. Amit and",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "Y. Shoshan and T. Tlusty",
		title: "Mammogram Classification with Ordered Loss, Artificial Intelligence in Medicine 2019 (Oral)-20% acceptance rate,",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Breast radiologists inspect mammograms with the utmost consideration to capture true cancer cases. Yet, machine learning models are typically designed to perform a binary classification, by joining several severities into one positive class. In such scenarios with mixed gradings, a reliable classifier would make less mistakes between distant severities such as missing a true cancer case and calling it as normal or vise versa. To this end, we suggest a simple yet elegant formulation for training a deep learning model with ordered loss, by increasingly weighting the loss of more severe cases, to enforce importance of certain errors over others. Training with the ordered loss yields fewer severe errors and can decrease the chances of missing true cancers. We evaluated our method on mammogram classification, using a weakly supervised deep learning method. Our data set included over 16K mammograms, with a large set of nearly 2,500 biopsy proven cancer cases. Evaluation of our proposed loss function showed a reduction in severe errors of missing true cancers, while preserving overall classification performance in the original task."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "Digital Mammography DREAM Challenge: The Core of Top Performing Methods, IEEE Biomedical and Health Informatics - Special Session, March 2018,",
		linkTo: "#",
		linkName: "Extended Abstract(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "The Digital Mammography DREAM (Dialog for Reverse Engineering Assessment and Methods) offered access to an unprecedented amount of curated data. Teams around the globe had the opportunity to tackle the computational diagnosis of screening mammography, with the vision of changing the work-flow for radiologists of the future. This work summarizes the main concepts behind the top performing methods in the competition phase of the challenge."
	},
	{
		namesBeforeRami: "A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul,",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and E. Barkan",
		title: "A Region Based Convolutional Neural Network for Mass Detection and Classification in Breast Mammography Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization (TCIV), 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "J. Sulam,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and P. Kisilev",
		title: "Maximizing AUC with Deep Learning for Classification of Imbalanced Mammogram Datasets Eurographics Workshop on Visual Computing for Biology and Medicine, 2017",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Breast cancer is the second most common cause of death in women. Common computer-aided diagnosis typically demand for carefully annotated data, precise tumor allocation and delineation of the boundaries, which is rarely available in the medical system. In this paper we present a new deep learning approach for classification of mammograms that requires only a global (binary) label. Traditional deep learning methods typically employ classification error losses, which are highly biased by class imbalance – a situation naturally arises in medical classification problems. We hereby suggest a novel loss measure that directly maximizes the Area Under the ROC Curve (AUC), providing an unbiased loss. We validate the proposed model on two mammogram datasets: IMG, comprising of 796 patients, 80 positive (164 images) and 716 negative (1869 images), and the publicly available dataset INbreast. Our results are encouraging, as the proposed scheme achieves an AUC of 0.76 and 0.65 for IMG and INbreast, respectively."
	},
	{
		namesBeforeRami: "G. Amit, O. Hadad, S. Alphert, T. Tlusty, Y. Gur,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and S. Hashoul",
		title: "Hybrid Mass Detection in Breast MRI combining Unsupervised Saliency Analysis and Deep Learning MICCAI, 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "A. Akselrod-Ballin, L. Karlinsky and S. Hashoul",
		title: "Domain Specific Convolutional Neural Nets for Detection of Architectural Distortion in Mammograms ISBI, 2017",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Detection of Architectural distortion (AD) is important for ruling out possible pre-malignant lesions in breast, but due to its subtlety, it is often missed on the screening mammograms. In this work we suggest a novel AD detection method based on region proposal convolution neural nets (R-CNN). When the data is scarce, as typically the case in medical domain, R-CNN yields poor results. In this study, we suggest a new R-CNN method addressing this shortcoming by using a pretrained network on a candidate region guided by clinical observations. We test our method on the publicly available DDSM data set, with comparison to the latest faster R-CNN and previous works. Our detection accuracy allows binary image classification (normal vs. containing AD) with over 80% sensitivity and specificity, and yields 0.46 false-positives per image at 83% true-positive rate, for localization accuracy. These measures significantly improve the best results in the literature."
	},
	{
		namesBeforeRami: "G. Amit",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "O. Hadad, E. Monovitch, N. Granot and S. Hashoul",
		title: "Classification of Breast MRI Lesions using Small-Size Training Sets: Comparison to Deep Learning Approaches SPIE-Medical Imaging, 2017",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Diagnostic interpretation of breast MRI studies requires meticulous work and high expertise. Computerized algorithms may assist radiologists by automatically characterizing the detected lesions. Deep learning approaches have shown promising results in natural image classification, but their applicability to medical imaging is limited by the deficiency of large annotated training sets. In this work, we address automatic classification of breast MRI lesions using two different deep learning approaches. We propose a novel image representation for dynamic contrast enhanced (DCE) breast MRI lesions, which combines the morphological discriminating between benign and malignant lesions: training a designated convolutional neural network and using a pre-trained deep network to extract features for a shallow classifier. The domain-specific trained network provided higher classification accuracy, compared to the pre-trained model, with area under the ROC curve of 0.91 vs. 0.81 and accuracy of 0.83 vs. 0.71. Similar accuracy was achieved in classifying benign lesions, malignant lesions and normal tissue images. The trained network was able to improve by using the multi-channel image representation, and was more robust to reductions in the size of the training set. A small-size convolutional neural network can learn to accurately classify findings in medical images using as little as few hundreds of images from few dozens of patients. With sufficient data augmentation, such network can be trained to outperform a pre-trained out-of-domain classifier. Development of domainspecific deep-learning models for medical imaging may facilitate technological advancements in computeraided diagnosis."
	},
	{
		namesBeforeRami: "A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E. Barkan",
		title: "A Region Based Convolutional Network for Tumor Detection and Classification in Breast Mammography MICCAI-DLMIA Workshop, 2016",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "This paper addresses the problem of detection and classification of tumors in breast mammograms. We introduce a novel system that integrates several modules including a breast segmentation module, and a fuzzy logic prior anatomical module for fibroglan ular tissue segmentation into a modified faster regionbased convolutional network. Our method is evaluated on a large multi-center clinical dataset and compared to ground truth annotated by expert radiologists. Preliminary experimental results show the high accuracy and efficiency obtained by the suggested network structure. As the volume and complexity of data in healthcare continues to accelerate generalizing such an approach may have a profound impact on patient care in many applications."
	},
	{
		namesBeforeRami: "S. Hashoul, E. Walach, A. Khateeb, A. Walach, G. Amit,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E. Barkan and P. Kisilev",
		title: "Efficiency of an automatic decision support system in facilitating diagnosis of Thyroid diseases RSNA 2016.",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "Y. Frommer,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and N. Kiryati",
		title: "Adaptive Shape from Focus with High order Derivatives IMVC 2016",
		linkTo: "#",
		linkName: "",
		achievement: "Best Student Paper",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "A. Zlotnick, S. Hashoul",
		title: "A Weakly Labeled Approach for Breast Tissue Segmentation and Breast Density Estimation in Digital Mammography, IEEE International Symposium on Bionmedical Imaging (ISBI) 2016.",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Breast tissue segmentation is a fundamental task in digital mammography. Commonly, this segmentation is applied prior to breast density estimation. However, observations show a strong correlation between the segmentation parameters and the breast density, resulting in a chicken and egg problem. This paper presents a new method for breast segmentation, based on training with weakly labeled data, namely breast density categories. To this end, a Fuzzy-logic module is employed computing an adaptive parameter for segmentation. The suggested scheme consists of a feedback stage where a preliminary segmentation is used to allow extracting domain specific features from an early estimation of the tissue regions. Selected features are then fed into a fuzzy logic module to yield an updated threshold for segmentation. Our evaluation is based on 50 fibroglandular delineated images and on breast density classification, obtained on a large data set of 1243 full-field digital mammograms. The data set contained images from different devices. The proposed analysis provided an average Jaccard spatial similarity coefficient of 0.4 with improvement of this measure in 70\% of cases where the suggested module was applied. In breast density classification, average classification accuracy of 75\% was obtained, which significantly improved the baseline method (67.4\%). Major improvement is obtained in low breast densities where higher threshold levels rejects false positive regions. These results show a promise for the clinical application of this method in breast segmentation, without the need for laborious tissue annotation."
	},
	{
		namesBeforeRami: "Y. Frommer,",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Kiryati",
		title: "Shape from Focus with Adaptive Focus Measure and High Order Derivatives, BMVC 2015,",
		linkTo: "#",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Shape From Focus (SFF) methods frequently use a single focus measure to obtain a depth map. Common focus measures are fixed and spatially invariant. In this paper we present a framework to create an adaptive focus measure based on ensemble of basis focus operators. Using the proposed framework we derive a new spatially variant focus measure obtained from linear combination of image derivatives. This approach effectively generalizes some of the existing measures. A new measure emerged from the proposed framework includes high order derivatives and presents a highly reliable focus measure. We rely on the focus curve standard deviation (CSTD) to determine the linear coefficients in our model. The emerged focus measure copes effectively with texture variation, strong intensity edges and depth discontinuities. Using CSTD we further suggest a new approach for aggregation in the focus volume succeeded by reconstruction based on the focus curve centroid. This different approach of aggregation and reconstruction yields improved depth maps, respecting shape smoothness and depth discontinuities for diversity of textured images. We assess the performance of our new approach by extensive experiments with highly realistic synthetic images and real images including two unique cases captured in the wild. In terms of focus measure, we significantly outperform the state-of-the-art, while presenting superior results comparing to two previously published alternatives."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "A Unified Approach for Registration and Depth in Depth from Defocus, IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(6), pp. 1041-1055, 2014.",
		linkTo: "#",
		linkName: "Publisher Link,",
		link2To: "#",
		link2Name: "Paper(PDF),",
		link3To: "#",
		link3Name: "Supplementary Material(PDF),",
		link4To: "#",
		link4Name: "Project Page.",
		achievement: "Editor's selection for spotlight paper",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Depth from Defocus (DFD) suggests a simple optical set-up to recover the shape of a scene through imaging with shallow depth of field. Although numerous methods have been proposed for DFD, less attention has been paid to the particular problem of alignment between the captured images. The inherent shift-variant defocus often prevents standard registration techniques from achieving the accuracy needed for successful shape reconstruction. In this paper, we address the DFD and registration problem in a unified framework, exploiting their mutual relation to reach a better solution for both cues. We draw a formal connection between registration and defocus blur, find its limitations and reveal the weakness of the standard isolated approaches of registration and depth estimation. The solution is approached by energy minimization. The efficiency of the associated numerical scheme is justified by showing its equivalence to the celebrated Newton-Raphson method and proof of convergence of the emerged linear system. The computationally intensive approach of DFD, newly combined with simultaneous registration, is handled by GPU computing. Experimental results demonstrate the high sensitivity of the recovered shapes to slight errors in registration and validate the superior performance of the suggested approach over two, separately applying registration and DFD alternatives."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A computationally efficient tracker with direct appearance-kinematic measure and adaptive Kalman filter, Journal of Real-Time Image Processing, online March 2013.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		link2To: "#",
		link2Name: "Project Page",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Depth from Defocus (DFD) suggests a simple optical set-up to recover the shape of a scene through imaging with shallow depth of field. Although numerous methods have been proposed for DFD, less attention has been paid to the particular problem of alignment between the captured images. The inherent shift-variant defocus often prevents standard registration techniques from achieving the accuracy needed for successful shape reconstruction. In this paper, we address the DFD and registration problem in a unified framework, exploiting their mutual relation to reach a better solution for both cues. We draw a formal connection between registration and defocus blur, find its limitations and reveal the weakness of the standard isolated approaches of registration and depth estimation. The solution is approached by energy minimization. The efficiency of the associated numerical scheme is justified by showing its equivalence to the celebrated Newton-Raphson method and proof of convergence of the emerged linear system. The computationally intensive approach of DFD, newly combined with simultaneous registration, is handled by GPU computing. Experimental results demonstrate the high sensitivity of the recovered shapes to slight errors in registration and validate the superior performance of the suggested approach over two, separately applying registration and DFD alternatives."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and G. Raveh",
		title: "Variational Depth from Defocus in Real-Time, The 3rd IEEE Workshop on GPU for Computer Vision ICCV, pp. 522-529, November 2011, Barcelona.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		link2To: "#",
		link2Name: "Presentation(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "With emerging of next generation of digital cameras offering a 3D reconstruction of a viewed scene, Depth from Defocus (DFD) presents an attractive option. In this approach the depth profile of the scene is recovered from two views captured in different focus setting. The DFD is well known as a computationally-intensive method due to the shift-variant filtering involved with its estimation. In this paper we present a parallel GPGPU implementation of DFD based on the variational framework, enabling computation up to 15 frames/sec for a SVGA sequence. This constitutes the first GPU application and the fastest implementation known for passive DFD. The speed-up is obtained by using the novel Fast Explicit Diffusion approach and the fine grain data parallelism in an explicit scheme. We evaluate our method on publicly available real data and compare its results to a recently published PDE based method. The proposed method outperforms previous DFD techniques in terms of accuracy/runtime, suggesting the DFD as an alternative for 3D reconstruction in real-time."
	},
	{
		namesBeforeRami: "S. Cohen and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "Image de-noising by Bayesian regression, 16th Int. Conference on Image Analysis and Processing (ICIAP), September 2011, Italy",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "We present a kernel based approach for image de-noising in the spatial domain. The crux of evaluation for the kernel weights is addressed by a Bayesian regression. This approach introduces an adaptive filter, well preserving edges and thin structures in the image. The hyper-parameters in the model as well as the predictive distribution functions are estimated through an efficient iterative scheme. We evaluate our method on common test images, contaminated by white Gaussian noise. Qualitative results show the capability of our method to smooth out the noise while preserving the edges and fine texture. Quantitative comparison with the celebrated total variation (TV) and several wavelet methods ranks our approach among state-of-the-art denoising algorithms. Further advantages of our method include the capability of direct and simple integration of the noise PDF into the de-noising framework. The suggested method is fully automatic and can equally be applied to other regression problems."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Stereo Matching with Mumford-Shah Regularization and Occlusion Handling, IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(11), pp. 2071-2084, 2010.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "Editor's selection for spotlight paper on the TPAMI Nov. 2010 Edition.<br>Performance ranked 4th out of 55 in the Middlebury Benchmark of Feb 2009, (Algo. VarMSOH - error threshold=0.5).",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "This paper addresses the problem of correspondence establishment in binocular stereo vision. We suggest a novel spatially continuous approach for stereo matching based on the variational framework. The proposed method suggests a unique regularization term based on Mumford-Shah functional for discontinuity preserving, combined with a new energy functional for occlusion handling. The evaluation process is based on concurrent minimization of two coupled energy functionals, one for domain segmentation (occluded vs. visible) and the other for disparity evaluation. In addition to a dense disparity map, our method also provides estimation for the half-occlusion domain, and a discontinuity function allocating the disparity/depth boundaries. Two new constraints are introduced improving the revealed discontinuity map. The experimental tests include a wide range of real data sets from Middlebury stereo database. The results demonstrate the capability of our method in calculating an accurate disparity function with sharp discontinuities and occlusion map recovery. Significant improvements are shown comparing to a recently published variational stereo approach. A comparison on the Middlebury stereo benchmark with sub-pixel accuracies shows that our method is currently among the top-ranked stereo matching algorithms."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N.Sochen",
		title: "A Geometric Framework and a New Criterion in Optical Flow Modeling, Journal of Mathematical Imaging and Vision, 33(2), pp. 178-194, February 2009.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "We evaluate the dense optical flow between two frames via variational approach. In this paper, a new framework for deriving the regularization term is introduced giving a geometric insight into the action of a smoothing term. The framework is based on the Beltrami paradigm in image denoising. It includes a general formulation that unifies several previous methods. Using the proposed framework we also derive two novel anisotropic regularizers incorporating a new criterion that requires co-linearity between the gradients of optical flow components and possibly the intensity gradient. We call this criterion &ldquo;alignment&rdquo; and reveal its existence also in the celebrated Nagel and Enkelmann&rsquo;s formulation. It is shown that the physical model of rotational motion of a rigid body, pure divergent/convergent flow and irrotational fluid flow, satisfy the alignment criterion in the flow field. Experimental tests in comparison to a recently published method show the capability of the new criterion in improving the optical flow estimations."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N.Sochen",
		title: "A Geometric Framework for Regularization of the Data Term in Stereo Vision, Journal of Mathematical Imaging and Vision, 331(1), pp. 17-33, May 2008.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "Every stereovision application must cope with the correspondence problem. The space of the matching variables, often consisting of spatial coordinates, intensity and disparity, is commonly referred as the data term (space). Since the data is often noisy a-priori preference is required constraining the evaluated disparity to be smooth (or piecewise smooth). It is shown that in the early local methods (e.g. window correlation techniques) a regularization is conducted on the data space. In the other hand, recent global methods consider a non-regularized data term with an added smoothing constraint implemented directly on the disparity. In this paper, we propose a new idea combining between the two latter approaches. To this end a novel geometric method for regularization of the data space is presented. The idea is then implemented on the state of the art variational method. Experimental results on the Middlebury real images demonstrate the qualitative and quantitative potential of the proposed approach."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and D. Aiger",
		title: "Geodesic Active Contours with Combined Shape and Appearance Priors, In Proc. Advanced Concepts in Intelligent Vision Systems (ACIVS), vol. 5259 of LNCS, pp. 494-505, 2008.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "We present a new object segmentation method that is based on geodesic active contours with combined shape and appearance priors. It is known that using shape priors can significantly improve object segmentation in cluttered scenes and occlusions. Within this context, we add a new prior, based on the appearance of the object, (i.e., an image) to be segmented. This method enables the appearance pattern to be incorporated within the geodesic active contour framework with shape priors, seeking for the object whose boundaries lie on high image gradients and that best fits the shape and appearance of a reference model. The output contour results from minimizing an energy functional built of these three main terms. We show that appearance is a powerful term that distinguishes between objects with similar shapes and capable of successfully segment an object in a very cluttered environment where standard active contours (even those with shape priors) tend to fail."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Variational Stereo Vision with Sharp Discontinuities and Occlusion Handling, In Proc. IEEE International Conference on Computer Vision (ICCV), pp. 1-7, 2007.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "This paper addresses the problem of correspondence establishment in binocular stereo vision. We suggest a novel variational approach that considers both the discontinuities and occlusions. It deals with color images as well as gray levels. The proposed method divides the image domain into the visible and occluded regions where each region is handled differently. The depth discontinuities in the visible domain are preserved by use of the total variation term in conjunction with the Mumford-Shah framework. In addition to the dense disparity and the occlusion maps, our method also provides a discontinuity function revealing the location of the boundaries in the disparity map. We evaluate our method on data sets from Middlebury site showing superior performance in comparison to the state of the art variational technique."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "A General Framework and New Alignment Criterion for Dense Optical Flow, In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, pp. 529-536, 2006.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "The problem of dense optical flow computation is addressed from a variational viewpoint. A new geometric framework is introduced. It unifies previous art and yields new efficient methods. Along with the framework a new alignment criterion suggests itself. It is shown that the alignment between the gradients of the optical flow components and between the latter and the intensity gradients is an important measure of the flow's quality. Adding this criterion as a requirement in the optimization process improves the resulting flow. This is demonstrated in synthetic and real sequences."
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Non-Isotropic Regularization of the Correspondence Space in Stereo Vision, In Proc. Int. Conference in Pattern Recognition (ICPR), vol. 4, pp. 293-296, 2004.",
		linkTo: "#",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "images/home-placeholder.jpg",
		abstractContent: "The correspondence problem in stereo vision is notoriously difficult. In many approaches a noisy solution is extracted from the correspondence space. Various sophisticated regularization techniques are applied then on this noisy solution. We study here the possibility to denoise the correspondence/correlation space before extracting the solution, by a non-linear and non-isotropic scheme. We show that this methods preserves edges (depth discontinuities) well and overcomes some of the problems encountered in previous approaches."
	},
	// other publications?????!!!!!
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A Prediction based Fast and Robust Tracker, Israel Machine Vision Conference, 2011.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A Real-Time and Robust Tracker for Robot Vision, The 3rd Israeli Conference on Robotics, 2010.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	// In Aerospace Sciences?????!!!!!!
	{
		namesBeforeRami: "A. Rosen and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "A Mathematical Modeling of Helicopter Track and Balance – Theory, Journal of Sound and Vibration, vol. 200(5), pp. 589-603, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and A. Rosen",
		title: "A Mathematical Modeling of Helicopter Track and Balance – Results, Journal of Sound and Vibration, vol. 200(5), pp. 605-620, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and A. Rosen",
		title: "Investigation of Helicopter Rotor Track and Balance, In Proc. of 37th Israel Annual Conference on Aerospace Sciences, pp. 308-319, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	}
];

var PublicationsTitleHtml = "snippets/Publications-title-snippet.html";
var PublicationsFirstRowHtml = "snippets/Publication-first-row-snippet.html";
var PublicationsOptionalRowHtml = "snippets/Publication-optional-row-snippet.html"
var HomeNewsHtml = "snippets/News-list-snippet.html";
var supervisionTitleHtml = "snippets/Supervision-title-snippet.html";
var supervisionHtml = "snippets/Supervision-snippet.html";
var NewsTitleHtml = "snippets/News-title-snippet.html";
var NewsHtml = "snippets/News-snippet.html";
var newsInterval;
var i = 0;

document.addEventListener("DOMContentLoaded", function (event) {
	pageTransformation('Home');
});

function pageTransformation (pageName) {
	clearInterval(newsInterval);
	document.querySelector(".page-on").className = "";
	document.querySelector("#" + pageName + "-option").className = "page-on";
	if (pageName == "Home") {
		i = 0;
		$ajaxUtils.sendGetRequest("snippets/" + pageName + "-snippet.html", function (responseText) {
			document.querySelector("#main-content").innerHTML = responseText;
		},
		false);
		waitForNewsToDisplay("#home-news-list", 100, newsArray);
		function waitForNewsToDisplay(selector, time, newsArray) {
	        if(document.querySelector(selector)!=null) {
	        	var newsOrder = newsOrderFunction(i);
				buildAndShowHomeNews(newsArray, newsOrder);
				newsInterval = setInterval(function () {
					var newsOrder = newsOrderFunction(i);
					// console.log(newsOrder);
					buildAndShowHomeNews(newsArray, newsOrder);
					i++;
					if (i == newsArray.length) {
						i = 0;
					}
				}, 3000)
	            return;
	        }
	        else {
	            setTimeout(function() {
	                waitForNewsToDisplay(selector, time, newsArray);
	            }, time);
	        }
	    }
	}

	if (pageName == "Publications") {
	    buildAndShowPublication(publicationsArray);
	}

	if (pageName == "Supervision") {
		buildAndShowSupervision(supervisionArray);
	}

	if (pageName == "News") {
		buildAndShowNews(newsArray);
	}
}

function newsOrderFunction (i) {
	var newsOrderArray = [];
	for (var j=0; j<4;) {
		if (i < 6) { //i<newsArray.length
			newsOrderArray[j] = i;
		}
		else {
			newsOrderArray[j] = i - 6; //i - newsArray.length
		}
		i++;
		j++;
	}
	// console.log(newsOrderArray);
	return newsOrderArray;
	// buildAndShowHomeNews(newsArray, newsOrderArray);
}

function insertProperty (string, propName, propValue) {
	var propToReplace = "{{" + propName + "}}";
	string = string.replace(RegExp(propToReplace, "g"), propValue);
	return string;
}

function buildAndShowHomeNews (newsArray, newsOrder) {
		$ajaxUtils.sendGetRequest(HomeNewsHtml, function(HomeNewsHtml) {
			var NewsViewHTML = buildHomeNewsViewHTML(newsArray, HomeNewsHtml, newsOrder);
			document.querySelector("#home-news-list").innerHTML = NewsViewHTML;
		}, false);
}

function buildHomeNewsViewHTML(newsArray, HomeNewsHtml, newsOrder) {
	var finalHtml = "";

	// console.log(newsOrder);
	// var max = i+4;
	// var j;

	// console.log("i:" + i);

	for (var k in newsOrder) {
		// console.log(newsOrder[k]);
		// console.log("k:" + k);
		// if (k >= newsArray.length) {
		// 	j = i;
		// 	console.log("j:" + j);
		// 	k = j - newsArray.length;
		// 	console.log("k:" + k);
		// }

		// if (k == 8) {
		// 	console.log("k = 8");
		// 	k = 0;
		// 	console.log("now k = " + k);
		// }
		// else {
		// 	console.log("k is not equal to 8");
		// }
		// k = parseInt(k);
		var html = HomeNewsHtml;
		var number = newsOrder[k]+1;
		var date = newsArray[newsOrder[k]].date;
		var startContent = newsArray[newsOrder[k]].startContent;
		var linkTo = newsArray[newsOrder[k]].linkTo;
		var linkName = newsArray[newsOrder[k]].linkName;
		var continueContent = newsArray[newsOrder[k]].continueContent;

		html = insertProperty(html, "number", number);
		html = insertProperty(html, "date", date);
		html = insertProperty(html, "startContent", startContent);
		html = insertProperty(html, "linkTo", linkTo);
		html = insertProperty(html, "linkName", linkName);
		html = insertProperty(html, "continueContent", continueContent);
		finalHtml += html;

		// k = j;
		// k++;
	}

	return finalHtml;
}

function buildAndShowPublication (publicationsArray) {
		$ajaxUtils.sendGetRequest(PublicationsTitleHtml, function(PublicationsTitleHtml) {
			$ajaxUtils.sendGetRequest(PublicationsFirstRowHtml, function(PublicationsFirstRowHtml) {
				$ajaxUtils.sendGetRequest(PublicationsOptionalRowHtml, function(PublicationsOptionalRowHtml) {
					var PublicationsViewHTML = buildPublicationsViewHTML(publicationsArray, PublicationsTitleHtml, PublicationsFirstRowHtml, PublicationsOptionalRowHtml);
					document.querySelector("#main-content").innerHTML = PublicationsViewHTML;
				}, false);
			}, false);
		}, false);
}

function buildPublicationsViewHTML(publicationsArray, PublicationsTitleHtml, PublicationsFirstRowHtml, PublicationsOptionalRowHtml) {
	var finalHtml = PublicationsTitleHtml;
	var smallHeaderRow = publicationsArray.length - 3;

	for (var j = 0; j<publicationsArray.length;) {
		var html = "";

		if (j == smallHeaderRow) {
			// html += "<hr id='hr'>";
			html += "<hr><h3>In Aerospace Sciences</h3>";
		}

		html += "<li>";
		html += PublicationsFirstRowHtml;

		var namesBeforeRami = publicationsArray[j].namesBeforeRami;
		var RamiBenAri = publicationsArray[j].RamiBenAri;
		var namesAfterRami = publicationsArray[j].namesAfterRami;
		var title = publicationsArray[j].title;
		var linkTo = publicationsArray[j].linkTo;
		var linkName = publicationsArray[j].linkName;
		var achievement = publicationsArray[j].achievement;

		html = insertProperty(html, "namesBeforeRami", namesBeforeRami);
		html = insertProperty(html, "RamiBenAri", RamiBenAri);
		html = insertProperty(html, "namesAfterRami", namesAfterRami);
		html = insertProperty(html, "title", title);
		html = insertProperty(html, "linkTo", linkTo);
		html = insertProperty(html, "linkName", linkName);
		html = insertProperty(html, "achievement", achievement);

		if (publicationsArray[j].link2To) {
			var link2To = publicationsArray[j].link2To;
			var link2Name = publicationsArray[j].link2Name;

			html = insertProperty(html, "link2To", link2To);
			html = insertProperty(html, "link2Name", link2Name);
		}
		if (publicationsArray[j].link3To) {
			var link3To = publicationsArray[j].link3To;
			var link3Name = publicationsArray[j].link3Name;

			html = insertProperty(html, "link3To", link3To);
			html = insertProperty(html, "link3Name", link3Name);
		}
		if (publicationsArray[j].link4To) {
			var link4To = publicationsArray[j].link4To;
			var link4Name = publicationsArray[j].link4Name;

			html = insertProperty(html, "link5To", link4To);
			html = insertProperty(html, "link5Name", link4Name);
		}
		if (publicationsArray[j].link5To) {
			var link5To = publicationsArray[j].link5To;
			var link5Name = publicationsArray[j].link5Name;

			html = insertProperty(html, "link5To", link5To);
			html = insertProperty(html, "link5Name", link5Name);
		}

		html = insertProperty(html, "link2To", "");
		html = insertProperty(html, "link2Name", "");
		html = insertProperty(html, "link3To", "");
		html = insertProperty(html, "link3Name", "");
		html = insertProperty(html, "link4To", "");
		html = insertProperty(html, "link4Name", "");
		html = insertProperty(html, "link5To", "");
		html = insertProperty(html, "link5Name", "");

		if (publicationsArray[j].imageSource !== "") {
			html += PublicationsOptionalRowHtml;

			var imageSource = publicationsArray[j].imageSource;
			var abstractContent = publicationsArray[j].abstractContent;

			html = insertProperty(html, "imageSource", imageSource);
			html = insertProperty(html, "abstractContent", abstractContent);
		}
		html += "</li>";
		finalHtml += html;

		j++;
	}
	finalHtml += "</ul>";
	return finalHtml;
}

function buildAndShowSupervision (supervisionArray) {
		$ajaxUtils.sendGetRequest(supervisionTitleHtml, function(supervisionTitleHtml) {
			$ajaxUtils.sendGetRequest(supervisionHtml, function(supervisionHtml) {
				var SupervisionViewHTML = buildSupervisionViewHTML(supervisionTitleHtml, supervisionHtml, supervisionArray);
				document.querySelector("#main-content").innerHTML = SupervisionViewHTML;
			}, false);
		}, false);
}

function buildSupervisionViewHTML(supervisionTitleHtml, supervisionHtml, supervisionArray) {
	var finalHtml = supervisionTitleHtml;

	for (var j = 0; j<supervisionArray.length;) {
		var html = supervisionHtml;

		var name = supervisionArray[j].name;
		var content = supervisionArray[j].content;

		html = insertProperty(html, "name", name);
		html = insertProperty(html, "content", content);

		finalHtml += html;

		j++;
	}
	finalHtml += "</ul></div>";
	return finalHtml;
}

function buildAndShowNews (newsArray) {
		$ajaxUtils.sendGetRequest(NewsTitleHtml, function(NewsTitleHtml) {
			$ajaxUtils.sendGetRequest(NewsHtml, function(NewsHtml) {
				var NewsViewHTML = buildNewsViewHTML(NewsTitleHtml, NewsHtml, newsArray);
				document.querySelector("#main-content").innerHTML = NewsViewHTML;
			}, false);
		}, false);
}

function buildNewsViewHTML(NewsTitleHtml, NewsHtml, newsArray) {
	var finalHtml = NewsTitleHtml;

	for (var j = 0; j<newsArray.length;) {
		var html = NewsHtml;

		var date = newsArray[j].date;
		var startContent = newsArray[j].startContent;
		var linkTo = newsArray[j].linkTo;
		var linkName = newsArray[j].linkName;
		var continueContent = newsArray[j].continueContent;

		html = insertProperty(html, "date", date);
		html = insertProperty(html, "startContent", startContent);
		html = insertProperty(html, "linkTo", linkTo);
		html = insertProperty(html, "linkName", linkName);
		html = insertProperty(html, "continueContent", continueContent);
		finalHtml += html;

		j++;
	}

	finalHtml += "</ul></div>";
	return finalHtml;
}
// function CVfunction () {
// 	if (confirm("The CV file will be downloaded to your computer as a PDF file")) {
// 		alert("Great. You're OK with it");
// 	}
// 	else {
// 		alert("OK, the file won't be downloaded");
// 	}
// }